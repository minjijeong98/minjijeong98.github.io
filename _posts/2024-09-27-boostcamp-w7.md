---
title: Boostcamp 7주차 회고
description: Boostcamp AI Tech 7기 NLP Track - 7주차 회고
author: mj
date: 2024-09-27 14:30:00 +0900
categories: [Activities, Boostcamp]
tags: [boostcamp, review, AI, NLP]
pin: true
---
## Main Events

우선은 대략적인 회고만 올려두고, 자세한 내용은 프로젝트에 대한 wrap-up 리포트 작성하고 코드 정리 하면서 좀 더 구체적으로 적어보겠다.
일주일동안 하루에 많아야 3시간씩 자면서 매달렸고, 지금은 너무 졸리다...
다음 주부터의 새로운 시작을 위해 주말 동안 결과를 깔끔하게 정리해야지... 정리하면서 이 회고도 같이 정리해보겠다.
오늘 곧 5시에 우리 팀의 프로젝트 발표가 있다. 떨린다,,, 화이팅

- 잘했던 것, 좋았던 것, 계속할 것
    - 내가 익숙하고, 잘 할 수 있는 데이터 핸들링 담당함. 데이터 분석에 기초한 데이터 전처리, LLM을 활용한 데이터 증강 등. 이를 통해 팀의 의사결정과 모델 성능 향상을 위한 다양한 시도에 기여할 수 있었음.
    - 매 과정에서 의식적으로 이유를 작성함. 내가 한 일들에 대해서는 이유를 명확히 정리하기 위해 노력했고, confluence에 잘 기록해둠
    - 하면 좋겠다 생각되거나, 다른 팀원이 제안해준 내용에 대해 빠르게 기능 구현하고 결과 확인해봄
    - 만들어진 코드에 모델명만 넣고 돌리는게 아니라, 코드를 찬찬히 살펴보며 전체 흐름을 이해하기 위해 노력함
    - streamlit을 이용한 데모 페이지 제작함. (팀 내, 팀 간, 또는 높으신 분들과의) 의사소통을 위해 현업에서 이런 시각화 자료가 얼마나 자주 요구되는지, 중요한지 느꼈는데, 이번 기회에 직접 페이지 기획하고 만들어보면서 Streamlit과 친숙해질 수 있었음.
    - github에서 git flow를 이용해 협업을 경험함.
- 잘못했던 것, 아쉬운 것, 부족한 것 → 개선 방향
    - 흐름에 집중하다보니, 어쩌면 중요한 기준이었을 리더보드 순위와 점수에는 큰 의미를 두지 않았다. 그래서 모델을 돌려보고 결과를 확인하기보다는 모델의 구조를 이해하는데 더 시간을 쏟았다. 다만 빠르게 여러 옵션 탐색하고 결과 내서, 이 수치를 개선하는 작업도 ML/DL에서 상당히 중요한 요소인 만큼, 수치상의 성능에도 더 신경써보자. (성능을 올리기보다는 강의에서 배운/들어봤던 다양한 툴을 써보는 것 자체에 초점이 있었던 것 같다)
    - 결과를 체계적으로 기록해두지 않은 점. 꼭 내가 돌린 모델이 아니라 하더라도, 각자 모델을 학습시키고 결과를 혼자 갖고 있다보니, 성능 향상을 위한 시도를 ‘감’에 의존하는 경향이 컸다. ‘이 쯤 하니까 좋은 것 같던데?’ 등… baseline 성능을 설정해두고, 이를 기준으로 삼은 뒤 탐색할 옵션을 정해서 table을 채워나가는,, 좀 더 체계적인 방식의 실험과 협업이 가능할 것으로 생각한다. 각자 다양한 시도를 해보는건 정말 좋지만, 기준점은 좀 더 명확이 있었으면 좋았을 것 같다.
    - 시간이 부족했다. 그렇다보니 제한된 시간 내에 다양한 시도를 하기 위해 각 방법에 대해 제대로 알아보고 공부하지 못한 채 우선 시도했다. 일을 한다기보다는 공부하는 과정인 만큼, 중간중간 잘 알아보고 공부하는 시간을 더 마련해야한다고 느꼈다. 강의를 다 듣고 프로젝트를 시작하려다보니 프로젝트 착수가 늦어져서 이렇게 된 것 같은데, 앞으로는 좀 더 빠르게 시작해보자.
- 도전할 것, 시도할 것
    - 흐름은 대략 이해했으니, 이제는 huggingface 코드를 바탕으로 딥러닝 학습용 코드를 제로부터 작성해보려 한다. 스트림릿으로 시각화하면서 torch.load()로 모델을 로딩하는 과정에 에러가 자주 발생했는데, 이 때 구글링해서 해법을 찾으면 대부분 AutoModel 기준으로 작성되어 있었다. 순수 torch 코드에는 적용하기 힘들거나 구조를 꽤 변경해야 하는 경우가 많았다. torch로 구현하면서 모델의 구조를 하나하나 뜯어보는 것도 좋지만, 우선은 transformer의 AutoModel을 사용해 쉽게 시작해보려 한다. AutoModel이 대중적이고, 참고할 자료가 많은 만큼 우선 AutoModel을 중심으로 코드 작성해볼 예정이다. 또, 이 코드 기반으로 peft, ensemble 등 적용 시도해보면서, 중간중간 수현님이 작성해주신 코드를 참고해볼 생각이다. 직접 짜보면, 왜 이 과정에서 이런 모듈/함수가 사용되었는지 잘 알 수 있을 것 같고, 또 내게는 낯선,,, 객체 지향 프로그래밍도 좀 더 익숙해질 수 있을 것 같다
    - 프로젝트 진행하면서 계속 ‘하이퍼파라미터를 어떻게 맞춰야 할까?’, ‘loss’는 뭐가, 왜 좋을까? ‘weight decay’는 뭐고, 어떤 범위에서 탐색해야 할까… 갈피를 잡기 힘들었다. 딥러닝에 대한 개념이 부족하기 때문이니, 딥러닝과 주요 하이퍼파라미터 핸들링 및 최적화 방법들을 찾아보고, 적용해보려 한다. 그런 면에서 빠르게, 계속 마음속에 담아두고 있던 앤드류 응의 딥러닝 강의를 다음주에 들어볼까 생각한다.
    - 하이퍼파라미터 탐색 하거나 다양한 옵션으로 모델 테스트 할 때 (같은 말인가?ㅎ), 좀 더 체계적으로 결과를 기록하며 진행해보겠다. MLFlow의 작동 방식 살펴보면서 W&B 또는 optuna와 어떤 차이를 갖는지 이해해보고, 동시에 cron-job 등? 모델 학습을 좀 더 자동화할 수 있는 방법을 탐색해보겠다.
- 피어 세션 리뷰
    - 이번 주 피어세션은 회의로 가득찼었다. 오전 스크럼 때 전 날 저녁부터 아침까지 진행했던 사항을 각자 공유하고, 오후 피어세션에서도 그 사이 시간에 진행한 내용을 공유했다. 때로는 1시간 반이 넘어가도록 회의가 진행됐는데, 그래도 회의가 반복될수록 다들 많이 의견을 나누고, 다음 할 일을 탐색할 수 있었던 것 같아 협업을 경험할 수 있었다.
    - confluence, github 이 두가지 툴을 중심으로 협업이 계속 진행되었는데, 이를 사용하며 기록의 중요성을 느낄 수 있었다. 다른 분이 피어세션 시간에 얘기했던 내용을 더 참고하고 싶어지면 기억에 의존하기보다 자세하게 정리된 문서를 참고할 수 있었고, 지난번 결정사항들을 회의록에서 확인하는 한편, github에 작성해주신 Readme 파일이나 다양한 가이드 글들을 보고 다른 팀원이 새로 추가해주신 기능들을 쉽게 쓸 수 있었다.
    - 부족한 리소스에서 하고 싶은게 참 많았던 일주일이었는데, 그 대부분을 시도해본 게 자랑스럽다~! 각자가 관심을 갖고 집중했던 영역은 조금씩 달랐지만, 다들 욕심과 흥미를 갖고 참여해서인지, 서로 맡아서 일을 하려는 모습이 인상적이었다. 나도 좋은 에너지를 많이 얻었고, 특히 코드를 작성하고 모델을 다루는 면에서 많이 배울 수 있었다.

